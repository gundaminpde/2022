{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVOAIgqkSe2fWkSEJp5/oU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gundaminpde/2022/blob/main/save_load_train_test_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "QsPkwkvdc9vK",
        "outputId": "da0ef8a6-cf95-4b42-ca7d-002195ea7359"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   0  \n",
              "1  0.0052  0.0044   0  \n",
              "2  0.0095  0.0078   0  \n",
              "3  0.0040  0.0117   0  \n",
              "4  0.0107  0.0094   0  \n",
              "\n",
              "[5 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78949f76-26c6-462c-8327-c8fe5e232e5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78949f76-26c6-462c-8327-c8fe5e232e5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78949f76-26c6-462c-8327-c8fe5e232e5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78949f76-26c6-462c-8327-c8fe5e232e5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 깃허브에 준비된 데이터를 가져옵니다.\n",
        "\n",
        "targetUrl=\"https://raw.githubusercontent.com/gundaminpde/2022/main/sonar3.csv\"\n",
        "\n",
        "\n",
        "# 광물 데이터를 불러옵니다. \n",
        "\n",
        "df = pd.read_csv(targetUrl, header=None)\n",
        "\n",
        "# 첫 5줄을 봅니다. \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막 5줄을 봅니다. \n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jo1rx_und-wQ",
        "outputId": "24da199f-6067-4774-e4c0-1a3b1520101c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0       1       2       3       4       5       6       7       8   \\\n",
              "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
              "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
              "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
              "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
              "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
              "\n",
              "         9   ...      51      52      53      54      55      56      57  \\\n",
              "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
              "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
              "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
              "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
              "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
              "\n",
              "         58      59  60  \n",
              "203  0.0193  0.0157   1  \n",
              "204  0.0062  0.0067   1  \n",
              "205  0.0077  0.0031   1  \n",
              "206  0.0036  0.0048   1  \n",
              "207  0.0061  0.0115   1  \n",
              "\n",
              "[5 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecc85a11-991b-4a8e-b048-d1c9a8871611\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecc85a11-991b-4a8e-b048-d1c9a8871611')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecc85a11-991b-4a8e-b048-d1c9a8871611 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecc85a11-991b-4a8e-b048-d1c9a8871611');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일반 암석(0)과 광석(1)이 몇 개 있는지 확인합니다.\n",
        "df[60].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIkQx-xOd7G4",
        "outputId": "f4c7593d-763d-4957-f95e-95928aec0717"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    111\n",
              "0     97\n",
              "Name: 60, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습셋과 테스트셋을 구분합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "8O0jBszpeJ4N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.25)) #Dropout 사용\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델을 컴파일합니다.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델을 실행합니다.\n",
        "history=model.fit(X_train, y_train, epochs=10, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1j36vIselmn",
        "outputId": "6af881f6-873c-4a5b-e468-7b9948e6286e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 0.6821 - accuracy: 0.5517\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5310\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.6069\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6207\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5655\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6276\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7172\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6759\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6069\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 테스트셋에 적용해 정확도를 구합니다. \n",
        "score=model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfSiytnewFd",
        "outputId": "4f4c21b9-6939-4249-ee62-e727d62ca2dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.7778\n",
            "Test accuracy: 0.7777777910232544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 이름과 저장할 위치를 함께 지정합니다. \n",
        "model.save('./data/model/my_model.hdf5') \n",
        "\n",
        "##hdf5 계층적 데이터 형식 (Hierarchical Data Format, HDF) 대용량의 데이터를 저장하기 위한 파일\n",
        "\n",
        "from tensorflow.keras.models import  load_model\n",
        "\n",
        "# 테스트를 위해 조금 전 사용한 모델을 메모리에서 삭제합니다.\n",
        "del model \n",
        "\n"
      ],
      "metadata": {
        "id": "fY7_DznNe5FD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 새로 불러옵니다.\n",
        "model = load_model('./data/model/my_model.hdf5') \n",
        "\n",
        "# 불러온 모델을 테스트셋에 적용해 정확도를 구합니다. \n",
        "score=model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_FvDrePfYX-",
        "outputId": "4dafe12f-b3c4-4b6d-89fe-ad4a10099272"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6083 - accuracy: 0.7778\n",
            "Test accuracy: 0.7777777910232544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 확인을 위한 긴 학습 \n",
        "history=model.fit(X_train, y_train, epochs=2000, batch_size=50, verbose=0, validation_split=0.25)\n",
        "\n",
        "# history에 저장된 학습 결과를 확인해 보겠습니다. \n",
        "hist_df=pd.DataFrame(history.history)\n",
        "hist_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_qyC8f8dop6N",
        "outputId": "15b41a4b-a003-4132-f590-5be387cda316"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          loss  accuracy  val_loss  val_accuracy\n",
              "0     0.591162  0.750000  0.609152      0.783784\n",
              "1     0.596521  0.731481  0.606970      0.783784\n",
              "2     0.605490  0.703704  0.605092      0.783784\n",
              "3     0.591182  0.759259  0.603134      0.783784\n",
              "4     0.599457  0.694444  0.601536      0.783784\n",
              "...        ...       ...       ...           ...\n",
              "1995  0.003683  1.000000  0.987434      0.783784\n",
              "1996  0.006112  1.000000  0.980072      0.783784\n",
              "1997  0.001797  1.000000  0.984445      0.783784\n",
              "1998  0.002611  1.000000  0.987511      0.783784\n",
              "1999  0.001737  1.000000  0.994613      0.783784\n",
              "\n",
              "[2000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceb10877-8766-436f-82fc-7a098b703e50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.591162</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.609152</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.596521</td>\n",
              "      <td>0.731481</td>\n",
              "      <td>0.606970</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.605490</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.605092</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.591182</td>\n",
              "      <td>0.759259</td>\n",
              "      <td>0.603134</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.599457</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>0.601536</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>0.003683</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.987434</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0.006112</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980072</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0.001797</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.984445</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0.002611</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.987511</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.001737</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994613</td>\n",
              "      <td>0.783784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceb10877-8766-436f-82fc-7a098b703e50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ceb10877-8766-436f-82fc-7a098b703e50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ceb10877-8766-436f-82fc-7a098b703e50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_vloss에 검증셋의 오차를 저장합니다.\n",
        "y_vloss=hist_df['val_loss']\n",
        "\n",
        "# y_loss에 학습셋의 오차를 저장합니다.\n",
        "y_loss=hist_df['loss']\n",
        "\n",
        "\n",
        "# x 값을 지정하고 검증셋의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yToWCi91p-Id",
        "outputId": "54171690-121e-429b-f34c-34d6f9d0038e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 학습 자동 \"저장\" \n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 깃허브에 준비된 데이터를 가져옵니다.\n",
        "\n",
        "targetUrl=\"https://raw.githubusercontent.com/gundaminpde/2022/main/sonar3.csv\"\n",
        "\n",
        "\n",
        "# 광물 데이터를 불러옵니다. \n",
        "\n",
        "df = pd.read_csv(targetUrl, header=None)\n",
        "\n",
        "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "\n",
        "# 학습셋과 테스트셋을 구분합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
        "\n",
        "\n",
        "# 모델을 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.25)) #Dropout 사용\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델을 컴파일합니다.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 저장의 조건을 설정합니다.\n",
        "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
        "\n",
        "# 모델을 실행합니다. \n",
        "history=model.fit(X_train, y_train, epochs=10, batch_size=50, validation_split=0.2, verbose=0, callbacks=[checkpointer])\n",
        "\n",
        "# verbose=장황하다.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50TBFM4mfdVq",
        "outputId": "f395bbcb-55d8-4f50-982f-d999d3e43cbc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: saving model to ./data/model/all/01-0.5517.hdf5\n",
            "\n",
            "Epoch 2: saving model to ./data/model/all/02-0.5172.hdf5\n",
            "\n",
            "Epoch 3: saving model to ./data/model/all/03-0.5172.hdf5\n",
            "\n",
            "Epoch 4: saving model to ./data/model/all/04-0.5172.hdf5\n",
            "\n",
            "Epoch 5: saving model to ./data/model/all/05-0.5517.hdf5\n",
            "\n",
            "Epoch 6: saving model to ./data/model/all/06-0.5172.hdf5\n",
            "\n",
            "Epoch 7: saving model to ./data/model/all/07-0.5172.hdf5\n",
            "\n",
            "Epoch 8: saving model to ./data/model/all/08-0.5172.hdf5\n",
            "\n",
            "Epoch 9: saving model to ./data/model/all/09-0.5172.hdf5\n",
            "\n",
            "Epoch 10: saving model to ./data/model/all/10-0.5172.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 학습 조기 종료\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "\n",
        "# 깃허브에 준비된 데이터를 가져옵니다.\n",
        "\n",
        "targetUrl=\"https://raw.githubusercontent.com/gundaminpde/2022/main/sonar3.csv\"\n",
        "\n",
        "\n",
        "# 광물 데이터를 불러옵니다. \n",
        "\n",
        "df = pd.read_csv(targetUrl, header=None)\n",
        "\n",
        "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "\n",
        "# 학습셋과 테스트셋을 구분합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
        "\n",
        "\n",
        "# 모델을 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.25)) #Dropout 사용\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델을 컴파일합니다.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# 학습이 언제 자동 중단 될지를 설정합니다.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "#최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
        "modelpath=\"./data/model/bestmodel.hdf5\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장합니다.\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "#모델을 실행합니다.\n",
        "history=model.fit(X_train, y_train, epochs=1000, batch_size=50, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohU69tjH3PCf",
        "outputId": "7f543677-fba7-4c3c-f917-cbf4b4309366"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3/3 [==============================] - 1s 111ms/step - loss: 0.7152 - accuracy: 0.4537 - val_loss: 0.6968 - val_accuracy: 0.5405\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6965 - accuracy: 0.5278 - val_loss: 0.6833 - val_accuracy: 0.6216\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6881 - accuracy: 0.5278 - val_loss: 0.6773 - val_accuracy: 0.6216\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.7029 - accuracy: 0.5093 - val_loss: 0.6769 - val_accuracy: 0.5946\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.6903 - accuracy: 0.5741 - val_loss: 0.6721 - val_accuracy: 0.6216\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.6789 - accuracy: 0.5463 - val_loss: 0.6680 - val_accuracy: 0.5946\n",
            "Epoch 7/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6835 - accuracy: 0.5648 - val_loss: 0.6652 - val_accuracy: 0.5946\n",
            "Epoch 8/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6678 - accuracy: 0.5833 - val_loss: 0.6637 - val_accuracy: 0.5946\n",
            "Epoch 9/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6663 - accuracy: 0.5926 - val_loss: 0.6674 - val_accuracy: 0.5946\n",
            "Epoch 10/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6820 - accuracy: 0.5556 - val_loss: 0.6723 - val_accuracy: 0.5946\n",
            "Epoch 11/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6478 - accuracy: 0.6019 - val_loss: 0.6796 - val_accuracy: 0.5135\n",
            "Epoch 12/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6483 - accuracy: 0.6296 - val_loss: 0.6813 - val_accuracy: 0.5135\n",
            "Epoch 13/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6744 - accuracy: 0.5648 - val_loss: 0.6791 - val_accuracy: 0.5135\n",
            "Epoch 14/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6582 - accuracy: 0.5648 - val_loss: 0.6756 - val_accuracy: 0.5135\n",
            "Epoch 15/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6623 - accuracy: 0.5926 - val_loss: 0.6664 - val_accuracy: 0.6216\n",
            "Epoch 16/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6446 - accuracy: 0.6296 - val_loss: 0.6578 - val_accuracy: 0.6216\n",
            "Epoch 17/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6375 - accuracy: 0.6481 - val_loss: 0.6521 - val_accuracy: 0.5946\n",
            "Epoch 18/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6519 - val_accuracy: 0.6216\n",
            "Epoch 19/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6514 - accuracy: 0.6574 - val_loss: 0.6537 - val_accuracy: 0.6216\n",
            "Epoch 20/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6442 - accuracy: 0.6296 - val_loss: 0.6544 - val_accuracy: 0.6216\n",
            "Epoch 21/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6393 - accuracy: 0.6481 - val_loss: 0.6549 - val_accuracy: 0.6216\n",
            "Epoch 22/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6377 - accuracy: 0.6481 - val_loss: 0.6556 - val_accuracy: 0.6216\n",
            "Epoch 23/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6158 - accuracy: 0.6944 - val_loss: 0.6557 - val_accuracy: 0.6216\n",
            "Epoch 24/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6154 - accuracy: 0.6852 - val_loss: 0.6527 - val_accuracy: 0.6216\n",
            "Epoch 25/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5993 - accuracy: 0.7222 - val_loss: 0.6486 - val_accuracy: 0.5946\n",
            "Epoch 26/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.6163 - accuracy: 0.6852 - val_loss: 0.6459 - val_accuracy: 0.5946\n",
            "Epoch 27/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6172 - accuracy: 0.7130 - val_loss: 0.6430 - val_accuracy: 0.5946\n",
            "Epoch 28/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5897 - accuracy: 0.6759 - val_loss: 0.6438 - val_accuracy: 0.5946\n",
            "Epoch 29/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6048 - accuracy: 0.7407 - val_loss: 0.6451 - val_accuracy: 0.5946\n",
            "Epoch 30/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5932 - accuracy: 0.6759 - val_loss: 0.6485 - val_accuracy: 0.5946\n",
            "Epoch 31/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5949 - accuracy: 0.7222 - val_loss: 0.6445 - val_accuracy: 0.5946\n",
            "Epoch 32/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5793 - accuracy: 0.7593 - val_loss: 0.6410 - val_accuracy: 0.6216\n",
            "Epoch 33/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5961 - accuracy: 0.6944 - val_loss: 0.6376 - val_accuracy: 0.6486\n",
            "Epoch 34/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5858 - accuracy: 0.6852 - val_loss: 0.6313 - val_accuracy: 0.6486\n",
            "Epoch 35/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.5800 - accuracy: 0.6852 - val_loss: 0.6223 - val_accuracy: 0.6757\n",
            "Epoch 36/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5895 - accuracy: 0.6944 - val_loss: 0.6160 - val_accuracy: 0.6757\n",
            "Epoch 37/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5953 - accuracy: 0.6667 - val_loss: 0.6179 - val_accuracy: 0.6757\n",
            "Epoch 38/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5560 - accuracy: 0.7963 - val_loss: 0.6117 - val_accuracy: 0.6757\n",
            "Epoch 39/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5855 - accuracy: 0.6944 - val_loss: 0.6034 - val_accuracy: 0.7027\n",
            "Epoch 40/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.5689 - accuracy: 0.7130 - val_loss: 0.6015 - val_accuracy: 0.7027\n",
            "Epoch 41/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5551 - accuracy: 0.7593 - val_loss: 0.6026 - val_accuracy: 0.7027\n",
            "Epoch 42/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5396 - accuracy: 0.7500 - val_loss: 0.6086 - val_accuracy: 0.6757\n",
            "Epoch 43/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5606 - accuracy: 0.7500 - val_loss: 0.6194 - val_accuracy: 0.6486\n",
            "Epoch 44/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5482 - accuracy: 0.7963 - val_loss: 0.6205 - val_accuracy: 0.6486\n",
            "Epoch 45/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5632 - accuracy: 0.7407 - val_loss: 0.6185 - val_accuracy: 0.6216\n",
            "Epoch 46/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5591 - accuracy: 0.7130 - val_loss: 0.6153 - val_accuracy: 0.6486\n",
            "Epoch 47/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5639 - accuracy: 0.7500 - val_loss: 0.6159 - val_accuracy: 0.6216\n",
            "Epoch 48/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5316 - accuracy: 0.7222 - val_loss: 0.6150 - val_accuracy: 0.6216\n",
            "Epoch 49/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5546 - accuracy: 0.7222 - val_loss: 0.6129 - val_accuracy: 0.6216\n",
            "Epoch 50/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5361 - accuracy: 0.7407 - val_loss: 0.6178 - val_accuracy: 0.5946\n",
            "Epoch 51/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5127 - accuracy: 0.7963 - val_loss: 0.6154 - val_accuracy: 0.5946\n",
            "Epoch 52/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.7407 - val_loss: 0.6084 - val_accuracy: 0.6216\n",
            "Epoch 53/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5221 - accuracy: 0.7593 - val_loss: 0.6031 - val_accuracy: 0.6216\n",
            "Epoch 54/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 0.7130 - val_loss: 0.6083 - val_accuracy: 0.5946\n",
            "Epoch 55/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.7778 - val_loss: 0.6144 - val_accuracy: 0.5946\n",
            "Epoch 56/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5270 - accuracy: 0.7222 - val_loss: 0.6104 - val_accuracy: 0.5946\n",
            "Epoch 57/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5268 - accuracy: 0.7685 - val_loss: 0.6060 - val_accuracy: 0.5946\n",
            "Epoch 58/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5176 - accuracy: 0.7037 - val_loss: 0.6065 - val_accuracy: 0.5946\n",
            "Epoch 59/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5266 - accuracy: 0.7222 - val_loss: 0.6082 - val_accuracy: 0.5946\n",
            "Epoch 60/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5025 - accuracy: 0.7870 - val_loss: 0.5950 - val_accuracy: 0.6216\n",
            "Epoch 61/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4984 - accuracy: 0.7963 - val_loss: 0.5913 - val_accuracy: 0.6216\n",
            "Epoch 62/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5022 - accuracy: 0.7778 - val_loss: 0.5986 - val_accuracy: 0.5946\n",
            "Epoch 63/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5002 - accuracy: 0.8056 - val_loss: 0.5982 - val_accuracy: 0.5946\n",
            "Epoch 64/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4802 - accuracy: 0.7778 - val_loss: 0.5875 - val_accuracy: 0.6486\n",
            "Epoch 65/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4802 - accuracy: 0.7963 - val_loss: 0.5815 - val_accuracy: 0.6486\n",
            "Epoch 66/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5196 - accuracy: 0.7037 - val_loss: 0.5800 - val_accuracy: 0.6486\n",
            "Epoch 67/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.4908 - accuracy: 0.7685 - val_loss: 0.5817 - val_accuracy: 0.6486\n",
            "Epoch 68/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4731 - accuracy: 0.7870 - val_loss: 0.5851 - val_accuracy: 0.6486\n",
            "Epoch 69/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4770 - accuracy: 0.7963 - val_loss: 0.5954 - val_accuracy: 0.5946\n",
            "Epoch 70/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4750 - accuracy: 0.7685 - val_loss: 0.6081 - val_accuracy: 0.5946\n",
            "Epoch 71/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4620 - accuracy: 0.8241 - val_loss: 0.6100 - val_accuracy: 0.5946\n",
            "Epoch 72/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4767 - accuracy: 0.7685 - val_loss: 0.5855 - val_accuracy: 0.6216\n",
            "Epoch 73/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4944 - accuracy: 0.7222 - val_loss: 0.5613 - val_accuracy: 0.6757\n",
            "Epoch 74/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4572 - accuracy: 0.7963 - val_loss: 0.5560 - val_accuracy: 0.6757\n",
            "Epoch 75/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4770 - accuracy: 0.8333 - val_loss: 0.5575 - val_accuracy: 0.7027\n",
            "Epoch 76/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.5526 - val_accuracy: 0.7027\n",
            "Epoch 77/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.5423 - val_accuracy: 0.7027\n",
            "Epoch 78/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4500 - accuracy: 0.7963 - val_loss: 0.5441 - val_accuracy: 0.6757\n",
            "Epoch 79/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.5500 - val_accuracy: 0.6757\n",
            "Epoch 80/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.5629 - val_accuracy: 0.6216\n",
            "Epoch 81/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4325 - accuracy: 0.8333 - val_loss: 0.5674 - val_accuracy: 0.5946\n",
            "Epoch 82/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4527 - accuracy: 0.7500 - val_loss: 0.5576 - val_accuracy: 0.6216\n",
            "Epoch 83/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.5475 - val_accuracy: 0.6757\n",
            "Epoch 84/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4529 - accuracy: 0.7407 - val_loss: 0.5562 - val_accuracy: 0.6216\n",
            "Epoch 85/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4681 - accuracy: 0.7870 - val_loss: 0.5736 - val_accuracy: 0.6216\n",
            "Epoch 86/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4530 - accuracy: 0.7685 - val_loss: 0.5613 - val_accuracy: 0.6216\n",
            "Epoch 87/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4213 - accuracy: 0.8056 - val_loss: 0.5434 - val_accuracy: 0.6486\n",
            "Epoch 88/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.4767 - accuracy: 0.7130 - val_loss: 0.5303 - val_accuracy: 0.6757\n",
            "Epoch 89/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4367 - accuracy: 0.8148 - val_loss: 0.5102 - val_accuracy: 0.7027\n",
            "Epoch 90/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4654 - accuracy: 0.7593 - val_loss: 0.5032 - val_accuracy: 0.7297\n",
            "Epoch 91/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4806 - accuracy: 0.7500 - val_loss: 0.5123 - val_accuracy: 0.7297\n",
            "Epoch 92/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4360 - accuracy: 0.7593 - val_loss: 0.5259 - val_accuracy: 0.7027\n",
            "Epoch 93/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4184 - accuracy: 0.8241 - val_loss: 0.5517 - val_accuracy: 0.6486\n",
            "Epoch 94/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4401 - accuracy: 0.8148 - val_loss: 0.5765 - val_accuracy: 0.6216\n",
            "Epoch 95/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.8148 - val_loss: 0.5569 - val_accuracy: 0.6486\n",
            "Epoch 96/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4128 - accuracy: 0.8426 - val_loss: 0.5445 - val_accuracy: 0.6486\n",
            "Epoch 97/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4600 - accuracy: 0.7593 - val_loss: 0.5435 - val_accuracy: 0.6486\n",
            "Epoch 98/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4378 - accuracy: 0.7963 - val_loss: 0.5588 - val_accuracy: 0.6486\n",
            "Epoch 99/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4299 - accuracy: 0.8241 - val_loss: 0.5826 - val_accuracy: 0.6216\n",
            "Epoch 100/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4172 - accuracy: 0.8148 - val_loss: 0.5933 - val_accuracy: 0.6216\n",
            "Epoch 101/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4302 - accuracy: 0.8056 - val_loss: 0.5682 - val_accuracy: 0.6486\n",
            "Epoch 102/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4209 - accuracy: 0.8056 - val_loss: 0.5408 - val_accuracy: 0.6486\n",
            "Epoch 103/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4046 - accuracy: 0.8333 - val_loss: 0.5414 - val_accuracy: 0.6486\n",
            "Epoch 104/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3988 - accuracy: 0.8241 - val_loss: 0.5552 - val_accuracy: 0.6486\n",
            "Epoch 105/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4145 - accuracy: 0.7963 - val_loss: 0.5517 - val_accuracy: 0.6486\n",
            "Epoch 106/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3984 - accuracy: 0.8426 - val_loss: 0.5472 - val_accuracy: 0.6486\n",
            "Epoch 107/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4441 - accuracy: 0.7593 - val_loss: 0.5323 - val_accuracy: 0.7297\n",
            "Epoch 108/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4052 - accuracy: 0.8148 - val_loss: 0.5214 - val_accuracy: 0.7568\n",
            "Epoch 109/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3922 - accuracy: 0.8241 - val_loss: 0.5204 - val_accuracy: 0.7568\n",
            "Epoch 110/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3966 - accuracy: 0.8241 - val_loss: 0.5286 - val_accuracy: 0.7297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### k겹 교차 검증\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# 깃허브에 준비된 데이터를 가져옵니다.\n",
        "\n",
        "targetUrl=\"https://raw.githubusercontent.com/gundaminpde/2022/main/sonar3.csv\"\n",
        "\n",
        "\n",
        "# 광물 데이터를 불러옵니다. \n",
        "\n",
        "df = pd.read_csv(targetUrl, header=None)\n",
        "\n",
        "\n",
        "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "# 몇 겹으로 나눌 것인지를 정합니다. \n",
        "k=5\n",
        "\n",
        "# KFold 함수를 불러옵니다. 분할하기 전에 샘플이 치우치지 않도록 섞어 줍니다.\n",
        "kfold = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# 정확도가 채워질 빈 리스트를 준비합니다.\n",
        "acc_score = []\n",
        "\n",
        "def model_fn():\n",
        "    model = Sequential() # 딥러닝 모델의 구조를 시작합니다.\n",
        "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# K겹 교차 검증을 이용해 k번의 학습을 실행합니다. \n",
        "for train_index , test_index in kfold.split(X):  # for 문에 의해서 k번 반복합니다. spilt()에 의해 k개의 학습셋, 테스트셋으로 분리됩니다.\n",
        "    X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]  \n",
        "    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model = model_fn()\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history=model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0) \n",
        "    \n",
        "    accuracy = model.evaluate(X_test, y_test)[1]  # 정확도를 구합니다.\n",
        "    acc_score.append(accuracy)  # 정확도 리스트에 저장합니다.\n",
        "\n",
        "# k번 실시된 정확도의 평균을 구합니다.\n",
        "avg_acc_score = sum(acc_score)/k\n",
        "\n",
        "# 결과를 출력합니다.\n",
        "print('정확도:', acc_score)\n",
        "print('정확도 평균:', avg_acc_score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEBxVXR7f3FS",
        "outputId": "dca2e29a-322c-486b-9689-ef63c4baeaa4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5896 - accuracy: 0.7857\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5756 - accuracy: 0.7619\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6452 - accuracy: 0.5714\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5925 - accuracy: 0.7561\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.7317\n",
            "정확도: [0.7857142686843872, 0.761904776096344, 0.5714285969734192, 0.7560975551605225, 0.7317073345184326]\n",
            "정확도 평균: 0.7213705062866211\n"
          ]
        }
      ]
    }
  ]
}